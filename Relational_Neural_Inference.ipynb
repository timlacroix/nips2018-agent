{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Relational_Neural_Inference.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timlacroix/nips2018-agent/blob/master/Relational_Neural_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS6qWID378AP",
        "colab_type": "text"
      },
      "source": [
        "# Neural Relational Inference\n",
        "\n",
        "In this session, we implement the ideas described in https://arxiv.org/pdf/1802.04687.pdf .\n",
        "Most of the code in the solution has been adapted from https://github.com/ethanfetaya/NRI .\n",
        "\n",
        "First add this drive folder to your own google drive account :\n",
        "https://drive.google.com/open?id=10Awx22Z8vah5MxBrCSgQGuQaS2HdG2ae\n",
        "\n",
        "Then follow these setup instructions. The `ls` should show one data folder and a utils.py file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4L1qRoN8CYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## SETUP\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWqIcOtf8oSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My\\ Drive/Summer_School\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRg_2aDa78AQ",
        "colab_type": "text"
      },
      "source": [
        "## Data, baselines and evaluations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grvv5Gl078AR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils import load_data\n",
        "\n",
        "loaders, location_range, velocity_range = load_data(batch_size=1, suffix='_springs5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfUs5pTv78AT",
        "colab_type": "text"
      },
      "source": [
        "### Plotting the input data\n",
        "\n",
        "<span style=\"color:red\">Find a good way to display the input data. Display both the particles and the relation matrix </span>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X06q8gxZ78AT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.style.use('seaborn-notebook')\n",
        "\n",
        "plt.figure(dpi=150)\n",
        "\n",
        "for x in loaders['train']:\n",
        "    num_atoms = 5\n",
        "    off_diag_idx = np.ravel_multi_index(\n",
        "        np.where(np.ones((num_atoms, num_atoms)) - np.eye(num_atoms)),\n",
        "        [num_atoms, num_atoms]\n",
        "    )\n",
        "    interactions = np.reshape(np.zeros((num_atoms, num_atoms)), [-1, 25])\n",
        "    interactions[0][off_diag_idx] = x[1]\n",
        "    interactions = np.reshape(interactions, [5,5])\n",
        "\n",
        "    atoms = []\n",
        "    for atom in range(num_atoms):\n",
        "        this_atom = []\n",
        "        for t in range(x[0].shape[2]):\n",
        "            datum = x[0][0][atom][t]\n",
        "            this_atom.append(datum.tolist())\n",
        "        this_atom = np.array(this_atom)\n",
        "        plt.scatter(this_atom[:, 0], this_atom[:, 1], s=3*np.sqrt(np.array(range(x[0].shape[2]))), alpha=0.5)\n",
        "        atoms.append(this_atom)\n",
        "    \n",
        "    for atom_a in range(num_atoms):\n",
        "        for atom_b in range(atom_a + 1, num_atoms):\n",
        "            if interactions[atom_a, atom_b] == 1:\n",
        "                for d1, d2 in zip(atoms[atom_a], atoms[atom_b]):\n",
        "                    plt.plot(\n",
        "                        [d1[0], d2[0]],\n",
        "                        [d1[1], d2[1]],\n",
        "                        'k-',\n",
        "                        linewidth = 1,\n",
        "                        alpha=0.2\n",
        "                    )\n",
        "                    \n",
        "    \n",
        "    break\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuVI0xht78AW",
        "colab_type": "text"
      },
      "source": [
        "## LSTM Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XuyUZTm78AX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "import pickle\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "suffix = '_springs5'\n",
        "n_atoms =  5\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "n_hidden = 256\n",
        "n_layers = 2\n",
        "\n",
        "batch_size = 128\n",
        "learning_rate = 5e-4\n",
        "dropout = 0\n",
        "temp = 0.5\n",
        "\n",
        "timesteps = 49\n",
        "prediction_steps = 10\n",
        "valid_freq = 1\n",
        "\n",
        "var = 5e-5\n",
        "\n",
        "loaders, location_range, velocity_range = load_data(batch_size=batch_size, suffix=suffix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDhROnRa78AY",
        "colab_type": "text"
      },
      "source": [
        "### Model\n",
        "<span style=\"color: red\">\n",
        "    Complete the following skeleton to implement the LSTM baseline described in the appendix of the paper.\n",
        "    <ul>\n",
        "        <li> step: outputs $x_{t+1} = x_t + \\delta$ and the new hidden layer </li>\n",
        "        <li> forward: run step for $b$ <em>burn-in</em> steps with true data as input. Then predict the rest of the sequence  </li>\n",
        "    </ul>\n",
        "</span>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDBBMrGt78AZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.functional import F\n",
        "\n",
        "class RecurrentBaseline(nn.Module):\n",
        "    \"\"\"LSTM model for joint trajectory prediction.\"\"\"\n",
        "\n",
        "    def __init__(self, n_in, n_hid, n_out, n_atoms, n_layers, do_prob=0.):\n",
        "        super(RecurrentBaseline, self).__init__()\n",
        "        \n",
        "        # Encode positions to n_hid dimensional space\n",
        "        self.pos_encoder = nn.Sequential(\n",
        "            nn.Linear(n_in, n_hid),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=do_prob),\n",
        "            nn.Linear(n_hid, n_hid),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        # RNN : n_atoms * n_hid -> n_atoms * n_hid. LSTM with n_layers.\n",
        "        self.rnn = nn.LSTM(n_atoms * n_hid, n_atoms * n_hid, n_layers)  # TODO\n",
        "\n",
        "        # Decode predicted configuration to physical location\n",
        "        self.pos_decoder = nn.Sequential(\n",
        "            nn.Linear(n_atoms * n_hid, n_atoms * n_hid),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_atoms * n_hid, n_atoms * n_out)\n",
        "        )\n",
        "\n",
        "    def step(self, ins, hidden=None):\n",
        "        # Input shape: [num_sims, n_atoms, n_in]\n",
        "        \n",
        "        # Apply first MLP to encode the coordinates\n",
        "        x = self.pos_encoder(ins).view(1, ins.size(0), -1)\n",
        "        \n",
        "        # Apply LSTM given hidden and encoded input\n",
        "        x, hidden = self.rnn(x, hidden)\n",
        "        x = x[0, :, :]\n",
        "        \n",
        "        # Apply second MLP to decode the output of the LSTM and compute delta\n",
        "        x = self.pos_decoder(x).view(ins.size(0), ins.size(1), -1)\n",
        "        x = x + ins\n",
        "\n",
        "        # Return both output and hidden\n",
        "        return x, hidden\n",
        "\n",
        "    def forward(self, inputs, burn_in_steps=1):\n",
        "        # Input shape: [num_sims, num_things, num_timesteps, n_in]\n",
        "\n",
        "        outputs = []\n",
        "        hidden = None\n",
        "\n",
        "        for step in range(0, inputs.size(2) - 1):\n",
        "            # If step <= burn_in_steps, the input is the true input\n",
        "            # Otherwise it's the output of the previous step\n",
        "            if step <= burn_in_steps:\n",
        "                ins = inputs[:, :, step, :]\n",
        "            else:\n",
        "                ins = outputs[step - 1]\n",
        "\n",
        "            output, hidden = self.step(ins, hidden)\n",
        "            outputs.append(output)\n",
        "\n",
        "        outputs = torch.stack(outputs, dim=2)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VesTtGqR78Aa",
        "colab_type": "text"
      },
      "source": [
        "### Eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrB_s_eP78Ab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(data_loader, model):\n",
        "    total_mse = 0\n",
        "    counter = 0\n",
        "\n",
        "    model.eval()\n",
        "    for batch_idx, (inputs, relations) in enumerate(data_loader):\n",
        "        inputs = inputs.cuda()\n",
        "        output = model(inputs, burn_in_steps=timesteps-prediction_steps)\n",
        "        target = inputs[:, :, 1:, :]\n",
        "\n",
        "        output = output[:, :, timesteps-prediction_steps:timesteps, :]\n",
        "        target = target[:, :, timesteps-prediction_steps:timesteps, :]\n",
        "        total_mse += ((target - output) ** 2).sum().item()\n",
        "        counter += inputs.shape[0]\n",
        "\n",
        "    return total_mse / counter\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4NYuDOn78Ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook, tnrange\n",
        "\n",
        "model = RecurrentBaseline(4, 256, 4, 5, 2, 0.2).cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "# TODO MOVE SOMEWHERE AND EXPLAIN\n",
        "def nll_gaussian(preds, target, variance):\n",
        "    neg_log_p = ((preds - target) ** 2 / (2 * variance))\n",
        "    return neg_log_p.sum() / (target.size(0) * target.size(1))\n",
        "\n",
        "# One epoch of training\n",
        "def train(epoch):\n",
        "    t = time.time()\n",
        "    loss_train = []\n",
        "    loss_val = []\n",
        "    mse_train = []\n",
        "    mse_val = []\n",
        "\n",
        "    model.train()\n",
        "    with tqdm_notebook(loaders['train'],  bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % (Fore.BLUE, Fore.RESET), desc=f'training') as t:\n",
        "        for data, relations in t:\n",
        "            data, relations = data.cuda(), relations.cuda()\n",
        "\n",
        "            output = model(data, burn_in_steps=timesteps-prediction_steps)\n",
        "\n",
        "            target = data[:, :, 1:, :]\n",
        "            loss = nll_gaussian(output, target, var)\n",
        "            mse = F.mse_loss(output, target)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train.append(loss.item())\n",
        "            mse_train.append(mse.item())\n",
        "            \n",
        "            t.set_postfix(loss=loss.item(), mse=mse.item())\n",
        "\n",
        "    return np.mean(loss_train), np.mean(mse_train) \n",
        "\n",
        "# Train model\n",
        "# t_total = time.time()\n",
        "# for epoch in tnrange(epochs):\n",
        "#     train_nll, train_mse = train(epoch)\n",
        "#     print(f\"train : {train_nll} (NLL) / {train_mse} (MSE)\")\n",
        "#     if (epoch + 1) % valid_freq == 0:\n",
        "#         test_mse = test(loaders['test'], model)\n",
        "#         print(f\"  test : {test_mse} (MSE)\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UKJVvOz78Ae",
        "colab_type": "text"
      },
      "source": [
        "## Neural Relational Inference model\n",
        "\n",
        "There are two parts to the model : an encoder that estimates the relation matrix and a decoder that produces a sequence given an estimation of the relation matrix.\n",
        "\n",
        "### The encoder\n",
        "The equations for the encoder in the paper are :\n",
        "$${\\bf h}^1_j = f_{emb}({\\bf x}_j)$$\n",
        "$$v\\rightarrow e:\\quad {\\bf h}^1_{(i,j)} = f_e^1([{\\bf h}^1_i, {\\bf h}^1_j])$$\n",
        "$$e\\rightarrow v:\\quad{\\bf h}^2_j = f_v^1\\big(\\sum_{i \\neq j}{\\bf h}^1_{(i,j)}\\big)$$\n",
        "$$v\\rightarrow e:\\quad{\\bf h}^2_{(i,j)} = f_e^2([{\\bf h}_i^2, {\\bf h}_j^2])$$\n",
        "\n",
        "Finally, we do a logistic regression on ${\\bf h}^2_{(i,j)}$ to obtain the probabilities of edge / non-edge.\n",
        "\n",
        "We will represent all functions as multi-layer perceptrons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-shQxHm78Af",
        "colab_type": "text"
      },
      "source": [
        "Let $f$ be the matrix of features such that row $f_i$ is the feature vector for node $i$. The implementation challenge in the encoder is to efficiently concatenate the $f_i$, $f_j$. We do this using ```index_select(input, dim, indices)```.\n",
        "\n",
        "Given an input of dimension $atoms \\times d$, create two index tensors such that for\n",
        "```python\n",
        "    x = torch.index_select(input, 0, id1)\n",
        "    y = torch.index_select(input, 0, id2)\n",
        "```\n",
        "We have $x_{i*atoms + j} = input_i$ and $x_{i*atoms + j} = input_j$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1tCfOH578Af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_atoms = 5\n",
        "d = 2\n",
        "features = torch.FloatTensor([[i] * d for i in range(n_atoms)])\n",
        "\n",
        "id1 = torch.LongTensor(sum([[i] * n_atoms for i in range(n_atoms)], []))  ## TODO\n",
        "id2 = torch.LongTensor(sum([list(range(n_atoms)) for i in range(n_atoms)], []))  ## TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G__uh3h78Ai",
        "colab_type": "text"
      },
      "source": [
        "We can now easily write the concatenation in the $v\\rightarrow e$ step:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LniowJXr78Aj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def v_to_e(x, id1, id2):\n",
        "    ## TODO\n",
        "    return torch.cat([\n",
        "        torch.index_select(x, 0, id1),\n",
        "        torch.index_select(x, 0, id2),\n",
        "    ], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7Gtj1bh78Al",
        "colab_type": "text"
      },
      "source": [
        "Read and understand this implementation of the aggregation in the $e \\rightarrow v$ step. Note that self-loops are considered here. We will fix that later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUz4cXj178Al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aggregator = torch.FloatTensor([\n",
        "    [1./n_atoms if row * n_atoms <= col < (row + 1) * n_atoms else 0 for col in range(n_atoms * n_atoms)]\n",
        "    for row in range(n_atoms)\n",
        "])\n",
        "\n",
        "def e_to_v(x, matrix):\n",
        "    return matrix @ x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZbmQdM078An",
        "colab_type": "text"
      },
      "source": [
        "In order to remove self-loops, we will use another index select. Given a tensor resulting from the v\\_to\\_e funciton above, write a function using index select that returns all edges except self edges. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMbdWVFz78An",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id3 = torch.LongTensor([\n",
        "    i for i in range(n_atoms * n_atoms)\n",
        "    if i not in set([j*n_atoms + j for j in range(n_atoms)])\n",
        "])\n",
        "\n",
        "# print(torch.index_select(v_to_e(features, id1, id2), 0, id3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glTzstK578Ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"Two-layer fully-connected ELU net with batch norm.\"\"\"\n",
        "\n",
        "    def __init__(self, n_in, n_hid, n_out, do_prob=0.):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(n_in, n_hid)\n",
        "        self.fc2 = nn.Linear(n_hid, n_out)\n",
        "        self.bn = nn.BatchNorm1d(n_out)\n",
        "        self.dropout_prob = do_prob\n",
        "\n",
        "    def batch_norm(self, inputs):\n",
        "        x = inputs.view(inputs.size(0) * inputs.size(1), -1)\n",
        "        x = self.bn(x)\n",
        "        return x.view(inputs.size(0), inputs.size(1), -1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Input shape: [num_sims, num_things, num_features]\n",
        "        x = F.elu(self.fc1(inputs))\n",
        "        x = F.dropout(x, self.dropout_prob, training=self.training)\n",
        "        x = F.elu(self.fc2(x))\n",
        "        return self.batch_norm(x)\n",
        "\n",
        "\n",
        "\n",
        "def ids_and_agg(n_atoms, no_self_edges=False):\n",
        "    n_for_agg = (n_atoms - 1) if no_self_edges else n_atoms\n",
        "    return (\n",
        "        torch.cuda.LongTensor(sum([[i] * n_atoms for i in range(n_atoms)], [])),\n",
        "        torch.cuda.LongTensor(sum([list(range(n_atoms)) for i in range(n_atoms)], [])),\n",
        "        torch.cuda.FloatTensor([\n",
        "            [1. / n_for_agg if row * n_for_agg <= col < (row + 1) * n_for_agg else 0\n",
        "             for col in range(n_for_agg * n_atoms)]\n",
        "            for row in range(n_atoms)\n",
        "        ]),\n",
        "        torch.cuda.LongTensor([\n",
        "            i for i in range(n_atoms * n_atoms)\n",
        "            if i not in set([j*n_atoms + j for j in range(n_atoms)])\n",
        "        ])\n",
        "    )\n",
        "\n",
        "class MLPEncoder(nn.Module):\n",
        "    def __init__(self, n_atoms, n_in, n_hid, n_out, do_prob=0.):\n",
        "        super(MLPEncoder, self).__init__()\n",
        "        self.mlp1 = MLP(n_in, n_hid, n_hid, do_prob)\n",
        "        self.mlp2 = MLP(n_hid * 2, n_hid, n_hid, do_prob)\n",
        "        self.mlp3 = MLP(n_hid, n_hid, n_hid, do_prob)\n",
        "        self.mlp4 = MLP(n_hid * 3, n_hid, n_hid, do_prob)\n",
        "        self.fc_out = nn.Linear(n_hid, n_out)\n",
        "        \n",
        "        self.id1, self.id2, self.aggregator, self.id3 = ids_and_agg(n_atoms)\n",
        "        \n",
        "    def tile(self, x):\n",
        "        return torch.cat([\n",
        "            torch.index_select(x, 1, self.id1),\n",
        "            torch.index_select(x, 1, self.id2),\n",
        "        ], 2)\n",
        "\n",
        "    def aggregate(self, x):\n",
        "        return self.aggregator @ x\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Input shape: [num_sims, num_atoms, num_timesteps, num_dims]\n",
        "        x = inputs.view(inputs.size(0), inputs.size(1), -1)\n",
        "        # New shape: [num_sims, num_atoms, num_timesteps*num_dims]\n",
        "        \n",
        "        x = self.mlp1(x)                  # eq 1\n",
        "        x_skip = self.mlp2(self.tile(x))       # eq 2\n",
        "        x = self.mlp3(self.aggregate(x_skip))  # eq 3\n",
        "        x = self.mlp4(torch.cat((self.tile(x), x_skip), dim=2))       # eq 4\n",
        "        \n",
        "        logits = self.fc_out(x)\n",
        "        return torch.index_select(logits, 1, self.id3)       # remove self-edges"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPKTVV3l78Aq",
        "colab_type": "text"
      },
      "source": [
        "Before adding the decoder, let's verify that this MLP Encoder can at least overfit the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UVugHfq78Aq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook, tnrange\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "n_atoms = 5\n",
        "model = MLPEncoder(n_atoms, int(4 * timesteps), 256, 2, 0.2).cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "def edge_accuracy(preds, target):\n",
        "    \"\"\"\n",
        "    :param preds: edge logits\n",
        "    :param target: ground truth\n",
        "    :return: precision of the prediction\n",
        "    \"\"\"\n",
        "    _, preds = preds.max(-1)\n",
        "    correct = preds.float().data.eq(\n",
        "        target.float().data.view_as(preds)).cpu().sum()\n",
        "    return np.float(correct) / (target.size(0) * target.size(1))\n",
        "\n",
        "# One epoch of training\n",
        "def train(epoch):\n",
        "    t = time.time()\n",
        "    loss_train = []\n",
        "    acc_train = []\n",
        "    loss = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "    model.train()\n",
        "    with tqdm_notebook(loaders['train'], 'training') as t:\n",
        "        for data, relations in t:\n",
        "            data, relations = data.cuda(), relations.cuda()\n",
        "            logits = model(data)\n",
        "            # TODO\n",
        "            l = loss(\n",
        "                logits,\n",
        "                torch.cat((\n",
        "                    (relations == 0)[:,:, None],\n",
        "                    (relations == 1)[:,:, None]\n",
        "                ), 2).float()\n",
        "            )\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "            edge_acc = edge_accuracy(logits, relations)\n",
        "            \n",
        "            loss_train.append(l.item())\n",
        "            acc_train.append(edge_acc)\n",
        "            \n",
        "            t.set_postfix(loss=l.item(), acc=edge_acc)\n",
        "\n",
        "    return np.mean(loss_train), np.mean(acc_train)\n",
        "\n",
        "# Train model\n",
        "t_total = time.time()\n",
        "best_epoch = 0\n",
        "for epoch in tnrange(2):\n",
        "    train_loss, train_acc = train(epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNO-aL2E78As",
        "colab_type": "text"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The equations of the recurrent decoder are :\n",
        "$$\n",
        "\\begin{aligned} v \\rightarrow e : \\tilde{\\mathbf{h}}_{(i, j)}^{t} &=\\sum_{k} z_{i j, k} \\tilde{f}_{e}^{k}\\left(\\left[\\tilde{\\mathbf{h}}_{i}^{t}, \\tilde{\\mathbf{h}}_{j}^{t}\\right]\\right) \\\\ e \\rightarrow v : \\operatorname{MSG}_{j}^{t} &=\\sum_{i \\neq j} \\tilde{\\mathbf{h}}_{(i, j)}^{t} \\\\ \\tilde{\\mathbf{h}}_{j}^{t+1} &=\\operatorname{GRU}\\left(\\left[\\operatorname{MSG}_{j}^{t}, \\mathbf{x}_{j}^{t}\\right], \\tilde{\\mathbf{h}}_{j}^{t}\\right) \\\\ \\boldsymbol{\\mu}_{j}^{t+1} &=\\mathbf{x}_{j}^{t}+f_{\\text { out }}\\left(\\tilde{\\mathbf{h}}_{j}^{t+1}\\right) \\\\ p\\left(\\mathbf{x}^{t+1} | \\mathbf{x}^{t}, \\mathbf{z}\\right) &=\\mathcal{N}\\left(\\boldsymbol{\\mu}^{t+1}, \\sigma^{2} \\mathbf{I}\\right) \\end{aligned}\n",
        "$$\n",
        "\n",
        "We will use only one edge type for simplicity. The last equation will be taken care of by the loss. Complete the following skeleton code for the `RNNDecoder` module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lHevAqY78At",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNDecoder(nn.Module):\n",
        "    \"\"\"Recurrent decoder module.\"\"\"\n",
        "\n",
        "    def __init__(self, n_dims, n_hid, do_prob=0.):\n",
        "        super(RNNDecoder, self).__init__()\n",
        "        # Linear, Tanh, Dropout, Linear, Tanh\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(2 * n_hid, n_hid), nn.Tanh(), nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, n_hid), nn.Tanh()\n",
        "        )\n",
        "        # GruCell\n",
        "        self.gru = nn.GRUCell(input_size=n_dims, hidden_size=n_hid)\n",
        "        # Linear, ReLU, Linear, ReLU, Linear\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(n_hid, n_hid), nn.ReLU(),\n",
        "            nn.Linear(n_hid, n_hid), nn.ReLU(),\n",
        "            nn.Linear(n_hid, n_dims)\n",
        "        )\n",
        "        self.n_dims = n_dims\n",
        "        self.n_hid = n_hid\n",
        "        \n",
        "        self.id1, self.id2, self.aggregator, self.id3 = ids_and_agg(n_atoms, True)\n",
        "        \n",
        "    def single_step_forward(self, inputs, edges, hidden):\n",
        "        hidden_state = torch.cat([\n",
        "            torch.index_select(hidden, 1, self.id1),\n",
        "            torch.index_select(hidden, 1, self.id2)\n",
        "        ], 2)\n",
        "        hidden_without_self = torch.index_select(hidden_state, 1, self.id3) * edges[:,:, 1].unsqueeze(2)\n",
        "        transformed = self.edge_mlp(hidden_without_self)\n",
        "        hidden_state = self.aggregator @ transformed\n",
        "        \n",
        "        next_hidden = self.gru(\n",
        "            inputs.contiguous().view(-1, self.n_dims),\n",
        "            hidden_state.view(-1, self.n_hid)\n",
        "        ).reshape(hidden.shape)\n",
        "        \n",
        "        output = self.decoder(next_hidden) + inputs\n",
        "\n",
        "        return output, next_hidden\n",
        "\n",
        "    def forward(self, data, edges, burn_in_steps=1):\n",
        "\n",
        "        inputs = data.transpose(1, 2).contiguous()\n",
        "\n",
        "        time_steps = inputs.size(1)\n",
        "\n",
        "        hidden = torch.zeros(inputs.size(0), inputs.size(2), self.n_hid).cuda()\n",
        "        pred_all = []\n",
        "\n",
        "        for step in range(inputs.size(1) - 1):\n",
        "            if step <= burn_in_steps:\n",
        "                ins = inputs[:, step, :, :]\n",
        "            else:\n",
        "                ins = pred_all[step - 1]\n",
        "\n",
        "            pred, hidden = self.single_step_forward(ins, edges, hidden)\n",
        "            pred_all.append(pred)\n",
        "\n",
        "        preds = torch.stack(pred_all, dim=1)\n",
        "\n",
        "        return preds.transpose(1, 2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOKPsITI78Au",
        "colab_type": "text"
      },
      "source": [
        "### Minimizing the negative ELBO\n",
        "\n",
        "Our goal is to minimize the following loss :\n",
        "$$\n",
        "\\mathcal{L}=-\\mathbb{E}_{q_{\\phi}(\\mathbf{z} | \\mathbf{x})}\\left[\\log p_{\\theta}(\\mathbf{x} | \\mathbf{z})\\right]+\\mathrm{KL}\\left[q_{\\phi}(\\mathbf{z} | \\mathbf{x}) \\| p_{\\theta}(\\mathbf{z})\\right]\n",
        "$$\n",
        "\n",
        "Complete the following skeleton code to compute the loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKelTu6-78Av",
        "colab_type": "text"
      },
      "source": [
        "### Putting it all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-qiO0eU78Av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn.functional import gumbel_softmax, softmax\n",
        "\n",
        "def kl_categorical_uniform(preds, num_atoms):\n",
        "    kl_div = preds * torch.log(preds + 1e-16)\n",
        "    return kl_div.sum() / (num_atoms * preds.size(0))\n",
        "\n",
        "def train(data_loader, optimizer, encoder, decoder):\n",
        "    loss_train = []\n",
        "\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    with tqdm_notebook(data_loader, desc=f'training') as t:\n",
        "        for data, relations in t:\n",
        "            data, relations = data.cuda(), relations.cuda()     \n",
        "\n",
        "            # Encode\n",
        "            logits = encoder(data)\n",
        "\n",
        "            # Compute edges with soft gumbel_softmax\n",
        "            edges = gumbel_softmax(\n",
        "                logits.view(-1, 2), tau=temp, hard=False\n",
        "            ).view(logits.shape)\n",
        "\n",
        "            # Decode using the edge weights\n",
        "            output = decoder(\n",
        "                data, edges, burn_in_steps=timesteps-prediction_steps\n",
        "            )\n",
        "\n",
        "            nll = nll_gaussian(\n",
        "                output, data[:,:,1:,:], var\n",
        "            )\n",
        "            kl = kl_categorical_uniform(\n",
        "                softmax(logits, 2), output.shape[1]\n",
        "            )\n",
        "            l = nll + kl\n",
        "            \n",
        "            edge_acc = edge_accuracy(logits, relations)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train.append(l.item())\n",
        "            t.set_postfix(loss=l.item(), nll = nll.item(), kl = kl.item(), acc=edge_acc)\n",
        "        \n",
        "    return np.mean(loss_train)\n",
        "\n",
        "dropout = 0\n",
        "n_dims = 4\n",
        "hidden = 256\n",
        "\n",
        "encoder = MLPEncoder(num_atoms, int(n_dims * timesteps), hidden, 2, dropout).cuda()\n",
        "decoder = RNNDecoder(n_dims, hidden, dropout).cuda()\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "    list(encoder.parameters()) + list(decoder.parameters()),\n",
        "    lr=learning_rate\n",
        ")\n",
        "\n",
        "for e in range(10):\n",
        "    loss = train(loaders['train'], optimizer, encoder, decoder)\n",
        "    print(f\"{loss}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdcBOL9r78Ax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}